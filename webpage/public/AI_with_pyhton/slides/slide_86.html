<!DOCTYPE html>
<html>
<head>
<title>Slide 86: Kernel Trick</title>
<style>
body {
  font-family: Arial, sans-serif;
  line-height: 1.6;
  margin: 20px;
}

.slide {
  border: 1px solid #ccc;
  padding: 20px;
  margin-bottom: 20px;
  background-color: #f9f9f9;
}

h1 {
  color: #333;
}

.explanation {
  margin-bottom: 15px;
}

.quiz {
  margin-top: 20px;
  border: 1px solid #ddd;
  padding: 15px;
  background-color: #eee;
}

.question {
  margin-bottom: 10px;
}

input[type="radio"] {
  margin-right: 5px;
}

button {
  background-color: #4CAF50;
  color: white;
  padding: 10px 15px;
  border: none;
  cursor: pointer;
}

button:hover {
  background-color: #3e8e41;
}

.answers {
  margin-top: 20px;
  border: 1px solid #ddd;
  padding: 15px;
  background-color: #f5f5f5;
  display: none; /* Hidden by default */
}

.correct-answer {
  color: green;
  font-weight: bold;
}
</style>
</head>
<body>

<div class="slide">
  <h1>Slide 86: Kernel Trick</h1>
  <h2>Instructions: Explain the kernel trick as a way to implicitly map data points to a higher-dimensional space.</h2>

  <div class="explanation">
    <p>The kernel trick is a powerful technique used in machine learning, particularly with Support Vector Machines (SVMs), to enable algorithms to operate in a high-dimensional, implicit feature space without explicitly computing the coordinates of the data in that space.  This is achieved by defining a kernel function, which computes the dot product between the images of all pairs of data in the feature space.</p>

    <p>Think of it this way: some datasets are not linearly separable in their original space. However, if we could transform these data points into a higher-dimensional space, they might become linearly separable. The kernel trick allows us to perform this transformation implicitly through kernel functions (e.g., radial basis function (RBF), polynomial kernel, sigmoid kernel).  We don't need to actually perform the complex and computationally expensive transformation; the kernel function computes the result of the dot product *as if* we had transformed the data.</p>

    <p>By using kernels, we avoid the computational cost and memory requirements of explicitly mapping the data into a higher-dimensional space. This makes it feasible to use complex models even with large datasets and high-dimensional data, where explicitly computing the feature space would be prohibitive.</p>
  </div>

  <div class="quiz">
    <h3>Quiz: Test Your Understanding</h3>

    <div class="question">
      <p>1. What is the primary benefit of using the kernel trick?</p>
      <label><input type="radio" name="q1" value="a"> A. Explicitly maps data to a higher-dimensional space.</label><br>
      <label><input type="radio" name="q1" value="b"> B. Implicitly computes the dot product in a higher-dimensional space without explicit mapping.</label><br>
      <label><input type="radio" name="q1" value="c"> C. Reduces the dimensionality of the data.</label><br>
      <label><input type="radio" name="q1" value="d"> D. Only works with linearly separable data.</label>
    </div>

    <div class="question">
      <p>2. Which of the following is an example of a kernel function?</p>
      <label><input type="radio" name="q2" value="a"> A. ReLU</label><br>
      <label><input type="radio" name="q2" value="b"> B. Sigmoid</label><br>
      <label><input type="radio" name="q2" value="c"> C. Polynomial Kernel</label><br>
      <label><input type="radio" name="q2" value="d"> D. Softmax</label>
    </div>

     <div class="question">
      <p>3. What problem does the kernel trick address?</p>
      <label><input type="radio" name="q3" value="a"> A. High computational cost of explicitly mapping data to a higher dimension.</label><br>
      <label><input type="radio" name="q3" value="b"> B. Difficulty in handling linearly separable data.</label><br>
      <label><input type="radio" name="q3" value="c"> C. Reducing model overfitting.</label><br>
      <label><input type="radio" name="q3" value="d"> D. Improving the accuracy of linear regression.</label>
    </div>


    <button onclick="revealAnswers()">Submit & Reveal Answers</button>

    <div class="answers" id="answers">
      <h3>Answer Key:</h3>
      <p>1. <span class="correct-answer">B. Implicitly computes the dot product in a higher-dimensional space without explicit mapping.</span></p>
      <p>2. <span class="correct-answer">C. Polynomial Kernel</span></p>
      <p>3. <span class="correct-answer">A. High computational cost of explicitly mapping data to a higher dimension.</span></p>
    </div>
  </div>
</div>

<script>
function revealAnswers() {
  document.getElementById("answers").style.display = "block";
}
</script>

</body>
</html>